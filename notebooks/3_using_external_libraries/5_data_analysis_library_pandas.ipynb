{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Data Analysis Library: Pandas \n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>NOTE</b>\n",
    "    <br>If you are using the Jupyter Hub provided for the IKON training, all the modules should be installed. In this case, please ignore the installation sections.\n",
    "</div>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This document will give a short introduction to one of the Python Data Analysis Library: `Pandas`.  \n",
    "\n",
    "`Pandas` is widely used in data science, machine learning, scientific computing, and many other data-intensive fields. Some of its advantages are:\n",
    "\n",
    "- data representation: easy to read, suited for data analysis \n",
    "- easy handling of missing data\n",
    "- easy to add/delete columns from `Pandas` data structures\n",
    "- data alignment: intelligent automatic label-based alignment\n",
    "- handling large datasets\n",
    "- powerful grouping of data\n",
    "- native to `Python`\n",
    "  \n",
    "`Pandas` provides rich data structures and indexing functionality to make it easy to reshape, slice and dice, perform aggregations, and select subsets of data. Its key data structures are called the _Series_ and _DataFrame_.\n",
    "\n",
    "A _Series_ is a one dimensional array-like object containing an array of data and an associated array of data labels, called its index.\n",
    "\n",
    "_DataFrames_ are two-dimensional tabular, column-oriented data structures with both row and column labels.\n",
    "\n",
    "## Installation\n",
    "\n",
    "You can install `pandas` using `pip` by typing the following command in a terminal:\n",
    "```\n",
    "python -m pip install pandas\n",
    "```\n",
    "or with `conda` \n",
    "\n",
    "```\n",
    "conda install pandas\n",
    "```\n",
    "\n",
    "or directly from a jupyter notebook:\n",
    "\n",
    "```\n",
    "import sys\n",
    "!{sys.executable} -m pip install pandas\n",
    "```\n",
    "\n",
    "To start using it, simply type:\n",
    "\n",
    "```\n",
    "import pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing\n",
    "You can change some of the settings of `Pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select number of decimals in the output display\n",
    "pd.set_option('display.precision', 6)\n",
    "\n",
    "# Set max rows displayed in output to 30\n",
    "pd.set_option(\"display.max_rows\", 30)\n",
    "\n",
    "# Set max columns displayed in output to 10\n",
    "pd.set_option(\"display.max_columns\", 10)\n",
    "\n",
    "# Set the style of date displayed in output: day first\n",
    "pd.set_option(\"display.date_dayfirst\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object creation\n",
    "## Series\n",
    "A Series is a 1D array-like object containing an array of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_series = pd.Series([4, 8, -10, np.nan, 2])\n",
    "first_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The representation of _first_series_ shows the index on the left and the values on the right. Here the default index format is used: integers _0_ to _N-1_, _N_ being the length of the data.  \n",
    "\n",
    "Note that missing values appear as _NaN_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Series from a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_series = pd.Series({'Entry1': 0.5, 'Entry2': 33., 'Entry3': 12.})\n",
    "second_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Series from a sub-selection of another Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_series = pd.Series(second_series, index=['Entry1', 'Entry4'])\n",
    "third_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding index names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_series.index = ['Row1', 'Row2', 'Row3', 'Row4', 'Row5']\n",
    "first_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing information on Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index object and the values can be accessed individually using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_series.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_series.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index can be used to access the values by a dictionary-like notation or by attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_series.Row1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_series['Row1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_series[['Row3', 'Row1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change values stored in the Series\n",
    "first_series['Row4'] = 8\n",
    "first_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering, scalar multiplication or mathematical functions can be applied to a _Series_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all positive values\n",
    "first_series[first_series > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply all values in the Series by 2\n",
    "first_series * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sine of all values\n",
    "np.sin(first_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A _Series_ can also be substituted into many functions that expect a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if `Row1` is in the Series\n",
    "'Row1' in first_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if `Row9` is in the Series\n",
    "'Row9' in first_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame\n",
    "\n",
    "A _DataFrame_ represents a spreadsheet-like data structure containing an ordered collection of columns. Each column can be a different value type: numeric, string, boolean, ...\n",
    "\n",
    "### Create a DataFrame using a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary\n",
    "first_data = {'Col_1': ['5', 2, '4', '7'],\n",
    "             'Col_2': [7, 8, 2, 1,],\n",
    "             'Col_3': [10, 4, 2, 1],\n",
    "             'Col_4': [5, 6, 7 , 1],\n",
    "             'Col_5': [9, 9, 2, 1],\n",
    "             'Col_6': [7, 8, 2, 1],}\n",
    "# convert dictionary to DataFrame\n",
    "first_df = pd.DataFrame(first_data)\n",
    "first_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some info about the created DataFrame\n",
    "first_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `Col_1` contains a mixture of integers and strings.\n",
    "\n",
    "### Viewing data\n",
    "\n",
    "Here is how to display the top and bottom rows of the frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the top 3 rows\n",
    "first_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the bottom 2 rows\n",
    "first_df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the index and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.to_numpy()` gives a `NumPy` representation of the data. \n",
    "\n",
    "This can be an expensive operation when the _DataFrame_ has columns with different data types.\n",
    "\n",
    "`DataFrame.to_numpy()` does not include the index or column labels in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`describe()` shows a quick statistic summary of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to transpose the data\n",
    "first_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting by an axis\n",
    "first_df.sort_index(axis=1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting by values\n",
    "first_df.sort_values(by=['Col_4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection\n",
    "`Pandas` supports several types of multi-axis indexing:\n",
    "\n",
    "- `.loc` to choose rows and columns by label. You have to specify rows and columns based on their row and column labels.  \n",
    "- `.iloc` to choose rows and columns by position. You have to specify rows and columns by their integer index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select index 2 i.e. the 3rd row of the DataFrame\n",
    "first_df.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we name the index, this name can also be used to extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_df.index = ['Row1', 'Row2', 'Row3', 'Row4']\n",
    "print(f\"DataFrame with named index:\\n{first_df}\")\n",
    "print(f\"\\nSelection of the 3rd row:\\n {first_df.loc['Row3']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting several rows\n",
    "# using index\n",
    "first_df[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# using name to select a sequence of rows\n",
    "first_df.loc['Row1':'Row3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Warning:**  \n",
    "Note that contrary to usual Python slices, both the start and the stop are included with `loc`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using name to select rows in a different order\n",
    "first_df.loc[['Row3', 'Row2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting several rows using their positions\n",
    "first_df.iloc[:, 2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the 4th row by position \n",
    "first_df.iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a single column. The output is a Series.\n",
    "first_df['Col_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(first_df['Col_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalent method to select a column\n",
    "first_df.Col_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting several columns using their names\n",
    "first_df.loc[:, 'Col_2':'Col_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting a subset of the DataFrame using positions\n",
    "first_df.iloc[1:3, 2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting a subset of the DataFrame using labels\n",
    "first_df.loc['Row2':'Row3', 'Col_3':'Col_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a single value using labels\n",
    "first_df.loc['Row3', 'Col_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a single value using positions\n",
    "first_df.iloc[2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get faster access to a scalar\n",
    "first_df.iat[2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boolean indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select section of DataFrame where the values of `Col_2` are larger than 2\n",
    "first_df[first_df['Col_2']> 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame\n",
    "second_df = pd.DataFrame(np.random.randn(6, 4), \n",
    "                         index=list('abcdef'), \n",
    "                         columns=list('ABCD'))\n",
    "second_df['E'] = ['one', 'one', 'three', 'two', 'three', 'four']\n",
    "second_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`isin()` can also be used for filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select row if value in 'E' column is 'three'\n",
    "second_df[second_df['E'].isin(['three'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting\n",
    "#### Adding column to a DataFrame\n",
    "Create a `Series` to be added to `second_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_to_add = pd.Series([1, 2, 3, 4, 5, 6], \n",
    "                    index=['a', 'b', 'd', 'e', 'g', 'h'])\n",
    "series_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_df['F'] = series_to_add\n",
    "second_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the index is aligned: the added series has additional entries `g` and `h` and no entries for `c` and `f`. The additional entries are discarded in the `DataFrame` and the absence of entry is marked as `NaN`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting values by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_df.at['b', 'A'] = 0\n",
    "second_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting values by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "second_df.iat[1, 0] = 0\n",
    "second_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a NumPy array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change all values in column 'C'\n",
    "second_df.loc[:, 'C'] = np.arange(len(second_df))\n",
    "second_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data\n",
    "\n",
    "`Pandas` uses `numpy.nan` to represent missing data. This value is by default not included in computations.\n",
    "\n",
    "#### Dropping rows with missing data\n",
    "The following command will remove rows `c` and `f` because they contain one `NaN` value.\n",
    "To filter rows containing only `NaN` values, replace `how='any'` by `how='all'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_df.dropna(axis=0, how='any', inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling missing data\n",
    "\n",
    "The following command replaces `NaN` by `8.33`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_df.fillna(value=8.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a mask \n",
    "`True` marks the `NaN` values in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(second_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Some of the methods to deal with missing data\n",
    "\n",
    "`DataFrame.isna` indicates missing values.  \n",
    "\n",
    "`DataFrame.notna` indicates existing (non-missing) values.\n",
    "\n",
    "`DataFrame.fillna` replaces missing values.  \n",
    "    \n",
    "`Series.dropna` drops missing values.  \n",
    "\n",
    "`Index.dropna` drops missing indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations\n",
    "#### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that column `E`, which contains strings, has been discarded to calculate the mean as well as `NaN` values in column `F`.  \n",
    "\n",
    "You can also specify which axis to calculate the mean. For example, to calculate the average for each row,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_df.mean(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply\n",
    "Use `apply` to apply a function along an axis of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_df = pd.DataFrame({'a': [1, 2, 3, 4, 5], 'b': [7, 8, 9, 10, 11]})\n",
    "third_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the square root of all elements in the DataFrame\n",
    "third_df.apply(np.sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the sum along one of the axes\n",
    "third_df.apply(np.sum, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_df.apply(np.sum, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge\n",
    "\n",
    "`Pandas` provides several tools to easily combine `Series` and `DataFrames`.\n",
    "\n",
    "##### concatenating objects with `concat()`\n",
    "Syntax:\n",
    "```\n",
    "pd.concat(objs, axis=0, join='outer', ignore_index=False, keys=None, levels=None,  \n",
    "names=None, verify_integrity=False, copy=True)\n",
    "```\n",
    "\n",
    "Simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'A': [1, 2, 3],\n",
    "                    'B': [4, 5, 6]})\n",
    "df2 = pd.DataFrame({'C': [-1, -2, -3],\n",
    "                    'D': [-4, -5, -6]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df1, df2], join='outer')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `join='inner'`, instead of getting the union of the DataFrames, \n",
    "we will get the intersection. For the 2 example DataFrames, the intersection is empty as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df1, df2], join='inner')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### concatenating using `append()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df1.append(df2)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### joining with `merge()`\n",
    "Syntax:\n",
    "```\n",
    "pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None,\n",
    "         left_index=False, right_index=False, sort=True,\n",
    "         suffixes=('_x', '_y'), copy=True, indicator=False,\n",
    "         validate=None)\n",
    "```\n",
    "Simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_df = pd.DataFrame({'key': ['0', '1'], 'lval': [1, 2]})\n",
    "right_df = pd.DataFrame({'key': ['0', '1', '2'], 'rval': [3, 4, 5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.merge(left_df, right_df, on='key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `how='right'`, only the keys of the right frame are used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left_df, right_df, on='key', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### joining on index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_df = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n",
    "                     'B': ['B0', 'B1', 'B2']},\n",
    "                     index=['Key0', 'Key1', 'Key2'])\n",
    "\n",
    "\n",
    "right_df = pd.DataFrame({'C': ['C0', 'C2'],\n",
    "                      'D': ['D0', 'D2']},\n",
    "                     index=['Key0', 'Key2'])\n",
    "\n",
    "result = left_df.join(right_df)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping\n",
    "“group by” is referring to a process involving one or more of the following steps:\n",
    "\n",
    "- **Splitting** data into groups based on some criteria\n",
    "\n",
    "- **Applying** a function to each group independently\n",
    "\n",
    "- **Combining** the results into a data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_group = {'Detectors': ['Det0', 'Det1', 'Det2', 'Det3', 'Det4',\n",
    "   'Det5', 'Det6', 'Det7', 'Det8', 'Det9', 'Det10', 'Det11'],\n",
    "   'GroupNb': [1, 2, 2, 3, 3, 4 , 1, 1, 2, 4, 1, 2],\n",
    "   'Counts': [2014, 153, 10 , 5300, 123, 2000, 1075, 217, 16, 1750, 500, 800],\n",
    "   'RunningOK': [True, True, False, False, True, True, True, True, False, True, True, True]}\n",
    "df_group = pd.DataFrame(data_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 'GroupNb' to group the DataFrame\n",
    "grouped = df_group.groupby('GroupNb') \n",
    "for name, group in grouped:\n",
    "    print(f'GroupNb: {name}')\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _DataFrame_ has been split into 4 groups according to the content of `GroupNb`.\n",
    "\n",
    "Below we group the _DataFrame_ according to `RunningOK` and then we sum the counts of `Det`s with `RunningOK=True`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group on value of RunningOK\n",
    "select_running_det = df_group.groupby(['RunningOK'])\n",
    "\n",
    "# Sum counts of all running \"Det\"s\n",
    "print(f\"Total count of running Dets: {select_running_det.get_group(True)['Counts'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply several functions to the groups at once \n",
    "select_running_det['Counts'].agg([np.sum, np.mean, np.std])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_plot = pd.DataFrame(np.concatenate((np.random.randn(100, 3), \n",
    "                np.sin(np.linspace(0,2*np.pi,100)).reshape(100,1)), axis=1),\n",
    "            index=pd.date_range('1/1/2000', periods=100), columns=['A', 'B', 'C', 'D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_to_plot.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting one column vs. another using a third column to color the points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_plot.plot.scatter(x='B', y='C', c='D', grid=True, s=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histograms**\n",
    "\n",
    "Histograms can be plotted using `DataFrame.plot.hist()` and `Series.plot.hist()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pd.DataFrame.plot.hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_to_plot.plot.hist(alpha=0.25, bins=25, grid=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame.hist()` plots the histograms of the columns on multiple subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_to_plot.hist(color='k', alpha=0.5, bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple DataFrame to write to files\n",
    "df_to_write_to_file = pd.DataFrame({\n",
    "    'A': ['one', 'one', 'two', 'three'] * 3,\n",
    "    'B': ['A', 'B', 'C'] * 4,\n",
    "    'C': ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 2,\n",
    "    'D': np.random.randn(12),\n",
    "    'E': np.random.randn(12)})\n",
    "\n",
    "df_to_write_to_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing a csv file\n",
    "df_to_write_to_file.to_csv('simple_file.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Options can be added when saving to a .csv file. For example:\n",
    "\n",
    "- Without the index  \n",
    "```\n",
    "df_to_write_to_file.to_csv('simple_file.csv', index=False)\n",
    "```  \n",
    "\n",
    "- Specify a custom delimiter for the CSV output; the default is a comma  \n",
    "```\n",
    "df_to_write_to_file.to_csv('simple_file.csv',sep='\\t') # Use Tab to separate data\n",
    "```\n",
    "\n",
    "- Dealing with missing values  \n",
    "```\n",
    "df_to_write_to_file.to_csv('simple_file.csv', na_rep='Unkown') # missing value saved as 'Unknown'\n",
    "```\n",
    "\n",
    "- Specifying the precision of the data written to file\n",
    "```\n",
    "df_to_write_to_file.to_csv('simple_file.csv', float_format='%.2f')\n",
    "```\n",
    "\n",
    "- Whether to export the column names  \n",
    "```\n",
    "df_to_write_to_file.to_csv('simple_file.csv', header=False)\n",
    "```\n",
    "\n",
    "- Select columns to be written in the .csv file. Default is None.    \n",
    "```\n",
    "df_to_write_to_file.to_csv('simple_file.csv',columns=['C'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading a csv file\n",
    "pd.read_csv('simple_file.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5\n",
    "\n",
    "An additional library `PyTables` is required to deal with HDF5 within `Pandas`. It can be installed within a notebook using\n",
    "\n",
    "```\n",
    "import sys\n",
    "!{sys.executable} -m pip install tables\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Writing an HDF5 file\n",
    "df_to_write_to_file.to_hdf('simple_file.h5', 'df_to_write_to_file', format='table', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading an HDF5 file\n",
    "pd.read_hdf('simple_file.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel\n",
    "Dealing with Excel files in `Pandas` requires `openpyxl`, `xlrd`.\n",
    "To be installed from a notebook:  \n",
    "```\n",
    "import sys\n",
    "!{sys.executable} -m pip install openpyxl xlrd\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing an Excel file\n",
    "df_to_write_to_file.to_excel('simple_file.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading an Excel file\n",
    "pd.read_excel('simple_file.xlsx', 'Sheet1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Exercises\n",
    "The solutions can be found in the _solutions_ folder of this repository.\n",
    "\n",
    "### How to combine series to form a dataframe?\n",
    "Combine `series1` and `series2` to form a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series1 = pd.Series(['a', 'b', 'c', 'd'])\n",
    "series2 = pd.Series([1, 2, 3, 4])\n",
    "\n",
    "# -- YOUR CODE HERE --\n",
    "# ---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to stack two series vertically and horizontally ?\n",
    "\n",
    "Stack `series1` and `series2` vertically and horizontally to form a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series1 = pd.Series(range(5))\n",
    "series2 = pd.Series(list('vwxyz'))\n",
    "\n",
    "# -- YOUR CODE HERE --\n",
    "# ---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to get the positions of items of series A in another series B?\n",
    "\n",
    "Get the positions of items of `series2` in `series1` as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series1 = pd.Series([10, 3, 6, 5, 3, 1, 12, 8, 23])\n",
    "series2 = pd.Series([1, 3, 5, 23])\n",
    "\n",
    "# -- YOUR CODE HERE --\n",
    "# ---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to compute difference of differences between consecutive numbers of a series?\n",
    "\n",
    "Difference of differences between the consecutive numbers of `series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series([1, 3, 6, 10, 15, 21, 27, 35])\n",
    "\n",
    "# Desired Output\n",
    "# [nan, 2.0, 3.0, 4.0, 5.0, 6.0, 6.0, 8.0]\n",
    "# [nan, nan, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --\n",
    "# ---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to check if a dataframe has any missing values?\n",
    "\n",
    "Check if `df` has any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(6, 4), \n",
    "                         index=list('abcdef'), \n",
    "                         columns=list('ABCD'))\n",
    "df['E'] = [0.5, np.nan, -0.33, np.nan, 3.14, 8]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --\n",
    "# ---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing with `groupby` and csv files\n",
    "\n",
    "- load the csv file [`biostats.csv`](https://people.sc.fsu.edu/~jburkardt/data/csv/biostats.csv) to a `users` DataFrame\n",
    "- determine the average, minimum and maximum ages per gender\n",
    "- determine the average weight of people over 35 years of age\n",
    "\n",
    "\n",
    "**Hint:** user `skipinitialspace=True` when reading the csv file to clean up the empty spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --\n",
    "# ---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://pandas.pydata.org/\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html\n",
    "\n",
    "Exercises:   \n",
    "https://www.w3resource.com/python-exercises/pandas/index.php  \n",
    "https://github.com/guipsamora/pandas_exercises/tree/master/03_Grouping/Occupation\n",
    "\n",
    "CSV files:  \n",
    "https://people.sc.fsu.edu/~jburkardt/data/csv/csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
